{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37232bit0bafe0d4bf6a43df845319a7cc4e1dd0",
   "display_name": "Python 3.7.2 32-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import requests\n",
    "from urllib.request import Request, urlopen\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_Name = [\"datascience\",\"machine Learning\"]\n",
    "number_of_Repositories  = 100\n",
    "repository_list = {}\n",
    "for name in topic_Name:\n",
    "    repository_list[name] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "for topic in topic_Name:\n",
    "    page_number = 1\n",
    "    repo_number = 0\n",
    "    while len(repository_list[topic]) < number_of_Repositories:\n",
    "        url = \"https://github.com/search?o=desc&p=\"+ str(page_number) +\"&q=\"+str(topic)+\"&s=stars&type=Repositories\"\n",
    "        data_page = requests.get(url)\n",
    "        main_data = BeautifulSoup(data_page.content,'html.parser')\n",
    "        for sub_data in main_data.findAll('li',attrs={'class':'repo-list-item'}):\n",
    "            repository_path = str(sub_data.findAll('a',attrs={'class':\"v-align-middle\"})[0].text)\n",
    "            repository_user_name , repository_name = repository_path.split('/')\n",
    "            repository_URL = \"https://github.com/\" + repository_path\n",
    "            repository_page = requests.get(repository_URL)\n",
    "            repository_data = BeautifulSoup(repository_page.content,'html.parser')\n",
    "            # ropository data\n",
    "            social_count = repository_data.findAll('a',attrs={'class':\"social-count\"})\n",
    "            repository_watch = social_count[0].text\n",
    "            repository_star = social_count[1].text\n",
    "            repository_fork = social_count[2].text\n",
    "            print(repository_watch,repository_star,repository_fork)\n",
    "            repository_list[topic].append(repository_path)\n",
    "            repo_number += 1\n",
    "            if (repo_number >= number_of_Repositories):\n",
    "                break\n",
    "        page_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Repositorie_list[\"machine Learning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}